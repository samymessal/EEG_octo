{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9364591e",
   "metadata": {},
   "source": [
    "# Sleep Spindle Detection\n",
    "## Data Preparation\n",
    "\n",
    "This notebook contains the preprocessing steps required for a sleep study dataset focusing on sleep spindles. The labels for sleep spindles are processed first, with the aim of identifying periods where sleep spindles are marked as present (`1`) or non-present (`0`). Various preprocessing steps, which are included in the `prepare_data()` function, can be applied to the data before training the model. Epochs are created around the marked events, each lasting for 2.5 seconds to match the reported duration of sleep spindles in the literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne  \n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import utils\n",
    "import feature_extraction\n",
    "from scipy.signal import detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097631c9",
   "metadata": {},
   "source": [
    "\n",
    "#### Data Preparation Function\n",
    "\n",
    "The `prepare_data` function is responsible for preparing EEG data by loading raw EEG recordings, applying preprocessing steps, and extracting epochs based on event markers. This process usually includes filtering to remove noise and artifacts, normalizing the data, and aligning the data with event markers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b493f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels_events(labels_df, labels=None):\n",
    "    if labels:\n",
    "        labels_df = labels_df[['Timestamp','Epochs'] + labels]\n",
    "        labels_events = np.zeros(len(labels_df), dtype=int)\n",
    "        labels_events[labels_df[labels[0]] == 1] = 0  # Assign 0 when labels[0] is 1\n",
    "        labels_events[labels_df[labels[1]] == 1] = 1  # Assign 1 when labels[1] is 1\n",
    "        time_events = labels_df['Timestamp'].values\n",
    "        events = np.column_stack((time_events, np.full(len(time_events), 1, dtype=int), labels_events))\n",
    "        return {'Labels': labels_events, 'Events': events}\n",
    "    else:\n",
    "        raise ValueError(\"Choose a label to include in the analysis\")\n",
    "\n",
    "def prepare_data(filepath_raw, filepath_labels, labels=None):\n",
    "    # Loading raw EEG data and creating Raw object\n",
    "    raw, raw_data, labels_df = utils.load_and_preprocess_data(filepath_raw, filepath_labels)\n",
    "\n",
    "    #Optional feature engineering\n",
    "\n",
    "    # raw._data = detrend(raw.get_data())\n",
    "    # raw._data = utils.vdm_raw(raw)\n",
    "    # raw = raw.notch_filter(50)\n",
    "    # raw.filter(11, 15)\n",
    "    # raw = raw.copy().crop(tmin=start_crop, tmax=end_crop)\n",
    "    # labels_df = process_eeg_events(labels_df, start_crop, end_crop, raw.info['sfreq'])\n",
    "\n",
    "    raw_data = raw.get_data()\n",
    "    labels_events, events = prepare_labels_events(labels_df, labels)\n",
    "\n",
    "    #Creating epochs around the events\n",
    "    epochs = mne.Epochs(raw,\n",
    "                        events, \n",
    "                        tmin=-0.5, tmax=2,\n",
    "                        baseline=None, preload=True)\n",
    "    \n",
    "    epochs = utils.normalize_epochs(epochs)\n",
    "        \n",
    "    return {'Epochs': epochs, 'Labels': labels_events}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83bf27",
   "metadata": {},
   "source": [
    "#### Combining Data\n",
    "\n",
    "The epochs data is combined to the features extracted in the previous section. We need to combine them respecting the input model format (n_samples, n_features, n_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_data(raw_filepaths, label_filepaths, labels, fmin, fmax):\n",
    "    all_epochs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Loop through each file path, prepare data, and collect epochs and labels\n",
    "    for raw_filepath, label_filepath in zip(raw_filepaths, label_filepaths):\n",
    "        data = utils.prepare_data(raw_filepath, label_filepath, labels)\n",
    "        all_epochs.append(data['Epochs'])\n",
    "        all_labels.append(data['Labels'])\n",
    "\n",
    "    # Combine epochs and labels from all datasets\n",
    "    combined_epochs = mne.concatenate_epochs(all_epochs)\n",
    "    combined_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Extract features for all combined epochs\n",
    "    X = feature_extraction.get_raw_feature_all(all_epochs, fmin, fmax)\n",
    "\n",
    "    return X, combined_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
