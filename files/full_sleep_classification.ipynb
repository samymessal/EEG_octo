{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samymessal/EEG_octo/blob/full_sleep_multi_label_classification/files/full_sleep_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783e24cf",
      "metadata": {
        "id": "783e24cf"
      },
      "source": [
        "\n",
        "# Sleep Spindle Study\n",
        "\n",
        "## Building Model\n",
        "\n",
        "In this notebook, we build a model to detect the presence of sleep spindles in the entire EEG recording.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Ij62zkKwkMJ6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij62zkKwkMJ6",
        "outputId": "9cdd3285-2862-435e-82a5-3b22054a18ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.6.0-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne) (0.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.11.17)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.6.0\n",
            "Collecting vmdpy\n",
            "  Downloading vmdpy-0.2-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vmdpy) (1.23.5)\n",
            "Installing collected packages: vmdpy\n",
            "Successfully installed vmdpy-0.2\n",
            "Collecting yasa\n",
            "  Downloading yasa-0.6.3.tar.gz (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yasa) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from yasa) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from yasa) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from yasa) (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from yasa) (0.12.2)\n",
            "Requirement already satisfied: mne>=0.23 in /usr/local/lib/python3.10/dist-packages (from yasa) (1.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from yasa) (0.58.1)\n",
            "Collecting outdated (from yasa)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting antropy (from yasa)\n",
            "  Downloading antropy-0.1.6.tar.gz (17 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from yasa) (1.2.2)\n",
            "Collecting tensorpac>=0.6.5 (from yasa)\n",
            "  Downloading tensorpac-0.6.5-py3-none-any.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.6/423.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyriemann>=0.2.7 (from yasa)\n",
            "  Downloading pyriemann-0.5.tar.gz (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.2/119.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sleepecg>=0.5.0 (from yasa)\n",
            "  Downloading sleepecg-0.5.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lspopt (from yasa)\n",
            "  Downloading lspopt-1.3.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from yasa) (7.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from yasa) (1.3.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from yasa) (4.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (4.66.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (1.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (23.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (3.1.2)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from mne>=0.23->yasa) (0.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->yasa) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from sleepecg>=0.5.0->yasa) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from sleepecg>=0.5.0->yasa) (2.31.0)\n",
            "Collecting stochastic (from antropy->yasa)\n",
            "  Downloading stochastic-0.7.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->yasa) (0.41.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->yasa) (3.0.9)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated->yasa) (67.7.2)\n",
            "Collecting littleutils (from outdated->yasa)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->yasa) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->yasa) (3.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->yasa) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->yasa) (6.3.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->yasa)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->yasa) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne>=0.23->yasa) (4.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->yasa) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->sleepecg>=0.5.0->yasa) (2023.11.17)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->yasa) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne>=0.23->yasa) (2.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->yasa) (0.8.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (5.5.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->yasa) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->yasa) (0.2.12)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (6.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.15.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->yasa) (2.21)\n",
            "Building wheels for collected packages: yasa, pyriemann, antropy, littleutils\n",
            "  Building wheel for yasa (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yasa: filename=yasa-0.6.3-py3-none-any.whl size=33800414 sha256=7a73ed586fcc12bc3c74888d3dac834bbbd64a4b3526ee41b8deb2ce8c211fad\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/d2/c1/9c3e43c2514650c9fe3805d37ceba9ff5e2c54484c489b3ba7\n",
            "  Building wheel for pyriemann (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyriemann: filename=pyriemann-0.5-py2.py3-none-any.whl size=107752 sha256=2c985b392e8652e64c61c8f1bc92be8d683318dbd40fbf1d214749bceec6ea50\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/86/79/622e9c1dc933dc088e287ebfaac5aa9bdc6a38a9db193ce1f1\n",
            "  Building wheel for antropy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antropy: filename=antropy-0.1.6-py3-none-any.whl size=16880 sha256=b1feaee4ed9447c05adfeb9ebdbe46b344f9db4324140b7813f3213da8ee8192\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/22/06/e91d7bb213c7133d5e2eb34258623e1e19928d5f05e1ee6812\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=50b277d7fc69341cd435b375bd3aac6889da72a3bea0e05fbc1763990ea22763\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built yasa pyriemann antropy littleutils\n",
            "Installing collected packages: littleutils, jedi, tensorpac, stochastic, sleepecg, outdated, lspopt, pyriemann, antropy, yasa\n",
            "Successfully installed antropy-0.1.6 jedi-0.19.1 littleutils-0.2.2 lspopt-1.3.0 outdated-0.2.2 pyriemann-0.5 sleepecg-0.5.6 stochastic-0.7.0 tensorpac-0.6.5 yasa-0.6.3\n"
          ]
        }
      ],
      "source": [
        "!pip install mne -q\n",
        "!pip install vmdpy -q\n",
        "!pip install yasa -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "YlBkcCPRkoy9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlBkcCPRkoy9",
        "outputId": "ddb2d8bc-1081-4d90-dc2f-6b231d3872f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEG_octo'...\n",
            "remote: Enumerating objects: 307, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 307 (delta 51), reused 66 (delta 20), pack-reused 198\u001b[K\n",
            "Receiving objects: 100% (307/307), 510.53 MiB | 23.17 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b full_sleep_multi_label_classification https://github.com/samymessal/EEG_octo\n",
        "import sys\n",
        "sys.path.append('/content/EEG_octo/files')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c44cdde",
      "metadata": {
        "id": "2c44cdde"
      },
      "source": [
        "\n",
        "## Imports\n",
        "\n",
        "We will import the necessary libraries that are needed for processing the data, building the model, and evaluating its performance.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "31dceae2",
      "metadata": {
        "id": "31dceae2"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "import json\n",
        "import data_preparation\n",
        "import preprocess\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import json\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM, Dense, BatchNormalization, Flatten, LayerNormalization\n",
        "import tensorflow.keras.layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.utils import timeseries_dataset_from_array\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import detrend\n",
        "import yasa\n",
        "from scipy.signal import welch\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Dropout, Flatten, Dense, Input, concatenate, Lambda\n",
        "from tensorflow.keras import Model, regularizers\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "DEFAULT_DIVIDER = 10000000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5642274",
      "metadata": {
        "id": "f5642274"
      },
      "source": [
        "### Download data\n",
        "\n",
        "Using the `processed_data` function from the previous step to download our concatenated raw with its correspondent preprocessing and features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "18bae3b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18bae3b7",
        "outputId": "19560e3c-6ceb-4868-d29f-7aeafef9cbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating RawArray with float64 data, n_channels=1, n_times=4965399\n",
            "    Range : 0 ... 4965398 =      0.000 ... 19861.592 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=4965399\n",
            "    Range : 0 ... 4965398 =      0.000 ... 19861.592 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=397232\n",
            "    Range : 0 ... 397231 =      0.000 ...  1588.924 secs\n",
            "Ready.\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:yasa:Hypnogram is SHORTER than data by 28.93 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 28.93 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 28.93 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 28.93 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 28.93 seconds. Padding hypnogram with last value to match data.size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating RawArray with float64 data, n_channels=1, n_times=5772730\n",
            "    Range : 0 ... 5772729 =      0.000 ... 23090.916 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=5772730\n",
            "    Range : 0 ... 5772729 =      0.000 ... 23090.916 secs\n",
            "Ready.\n",
            "Creating RawArray with float64 data, n_channels=1, n_times=461818\n",
            "    Range : 0 ... 461817 =      0.000 ...  1847.268 secs\n",
            "Ready.\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:yasa:Hypnogram is SHORTER than data by 17.27 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 17.27 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 17.27 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 17.27 seconds. Padding hypnogram with last value to match data.size.\n",
            "WARNING:yasa:Hypnogram is SHORTER than data by 17.27 seconds. Padding hypnogram with last value to match data.size.\n"
          ]
        }
      ],
      "source": [
        "def load_eeg_data(mat_file_path):\n",
        "    # Load the .mat file using scipy\n",
        "    mat = loadmat(mat_file_path)\n",
        "    # Extract EEG data\n",
        "    return mat['EEG'][0, 0]['data']\n",
        "\n",
        "def mk_raw_obj(eeg_data, sfreq=250):\n",
        "    info = mne.create_info(\n",
        "        ch_names=[f'EEG{i}' for i in range(len(eeg_data))],\n",
        "        sfreq=sfreq,\n",
        "        ch_types=['eeg' for _ in range(len(eeg_data))]\n",
        "    )\n",
        "\n",
        "    return mne.io.RawArray(eeg_data, info)\n",
        "\n",
        "def load_data(file_path, labels_path):\n",
        "    raw_mat = load_eeg_data(file_path)\n",
        "    raw = mk_raw_obj(raw_mat)\n",
        "    raw_data = raw.get_data()\n",
        "    labels = pd.read_csv(labels_path)\n",
        "    labels.sort_values(\"Timestamp\", inplace=True)\n",
        "    return raw, raw_data, labels\n",
        "\n",
        "def mne_events_from_labels_df(recording_raw_obj: mne.io.Raw, labels_df: pd.DataFrame, target_label: str,):\n",
        "    presence_mask = labels_df[target_label] == 1\n",
        "    nb_events = len(labels_df[presence_mask])\n",
        "\n",
        "    return np.column_stack((labels_df['Timestamp'][presence_mask], np.ones(nb_events), np.ones(nb_events)))\n",
        "\n",
        "\n",
        "def preprocess_data(recording_data,\n",
        "                    frequency_band,\n",
        "                    sampling_freq,\n",
        "                    resampling_freq,\n",
        "                    labels_df,\n",
        "                    target_label,\n",
        "                    window_size_in_seconds):\n",
        "    # Detrending\n",
        "    recording_data = detrend(recording_data)\n",
        "\n",
        "    # Create mne raw obj\n",
        "    recording_raw_obj = mk_raw_obj(recording_data)\n",
        "    events = mne_events_from_labels_df(recording_raw_obj, labels_df, target_label)\n",
        "\n",
        "    # Resampling\n",
        "    recording_raw_obj, events = recording_raw_obj.resample(resampling_freq, events=events)\n",
        "    labels_df = pd.DataFrame(events, columns=[\"Timestamp\", \"ignore\", target_label])\n",
        "\n",
        "    # Band pass filtering\n",
        "    raw_obj = mk_raw_obj(recording_data, sfreq=sampling_freq)\n",
        "    bp_filter_raw_obj = raw_obj.filter(frequency_band[0], frequency_band[1], verbose=0)\n",
        "    recording_data = bp_filter_raw_obj.get_data()\n",
        "\n",
        "    return recording_raw_obj, labels_df\n",
        "\n",
        "def hypnogram_propas(recording_raw_obj, sampling_freq=250):\n",
        "    \"\"\"\n",
        "    Computes the propabilites of the each sleep stages at each 30s epoch.\n",
        "    Then, upsamples the probabilites to match the shape of the recording.\n",
        "    ### Parameters:\n",
        "    recording_data: ndarray of the recording\n",
        "    ### Returns:\n",
        "    Tuple of shape four, each item is a 1D array of the probability of a sleep stage at a given timestamp.\n",
        "    Four for the four sleep stages: awake, REM, NREM1, NREM2, NREM3\n",
        "    \"\"\"\n",
        "    # For some reason, yasa doesn't work properly with the unscaled data.\n",
        "    scalled_raw_obj = mk_raw_obj(recording_raw_obj.get_data() / DEFAULT_DIVIDER, sfreq=sampling_freq)\n",
        "    sls = yasa.SleepStaging(scalled_raw_obj, eeg_name=\"EEG0\")\n",
        "    hypno_proba = sls.predict_proba()\n",
        "    return [yasa.hypno_upsample_to_data(hypno_proba[column], 1/30, scalled_raw_obj, verbose=False) for column in hypno_proba.columns]\n",
        "\n",
        "def dataset_from_files(\n",
        "        recording_files,\n",
        "        labels_files,\n",
        "        target_label,\n",
        "        resampling_freq,\n",
        "        sampling_freq,\n",
        "        frequency_band,\n",
        "        window_size_in_seconds,\n",
        "        shuffle=False\n",
        "        ):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the EEG recordings.\n",
        "    Returns a dataset keras obj.\n",
        "\n",
        "    ### Parameters:\n",
        "    recording_files: List of tuples of (.mat single channel eeg_recording\n",
        "    labels_files: .csv recording labels\n",
        "    sampling_freq: sampling frequency of the recording.\n",
        "    target_label: target label\n",
        "    frequency_band: tuple (min frequency, max frequency), if not None, used to band pass filter the recordings\n",
        "\n",
        "    ### Returns:\n",
        "    (dataset, window_size)\n",
        "    dataset: Timeseries dataset keras obj\n",
        "    window_size: window size in timestamps after resampling\n",
        "    \"\"\"\n",
        "    time_series = []\n",
        "    target_timeseries = []\n",
        "    for recording_file, labels_file in zip(recording_files, labels_files):\n",
        "        # Loading\n",
        "        labels_df = pd.read_csv(labels_file)\n",
        "        recording_data = load_eeg_data(recording_file)\n",
        "\n",
        "        # Preprocessing\n",
        "        preprocessed_recording_raw_obj, labels_df = preprocess_data(\n",
        "            recording_data,\n",
        "            frequency_band,\n",
        "            sampling_freq,\n",
        "            resampling_freq,\n",
        "            labels_df,\n",
        "            target_label,\n",
        "            window_size_in_seconds\n",
        "            )\n",
        "\n",
        "        # Feature engineering\n",
        "        hypno_propas = hypnogram_propas(preprocessed_recording_raw_obj, sampling_freq=sampling_freq)\n",
        "\n",
        "        # Features formatting\n",
        "        time_serie = np.column_stack((\n",
        "            preprocessed_recording_raw_obj.get_data().squeeze(),\n",
        "            *hypno_propas,\n",
        "            ))\n",
        "        target_timeserie = np.zeros(time_serie.shape[0])\n",
        "        for timestamp in labels_df[\"Timestamp\"]:\n",
        "          target_timeserie[int(timestamp)] = 1\n",
        "        time_series.append(time_serie)\n",
        "        target_timeseries.append(target_timeserie)\n",
        "\n",
        "    concat_timeseries = np.concatenate(time_series)\n",
        "    concat_target_timeseries = np.concatenate(target_timeseries)\n",
        "\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(concat_target_timeseries), y=concat_target_timeseries)\n",
        "    window_size = int(window_size_in_seconds * resampling_freq)\n",
        "    dataset = timeseries_dataset_from_array(\n",
        "        concat_timeseries,\n",
        "        concat_target_timeseries,\n",
        "        window_size,\n",
        "        shuffle=shuffle\n",
        "        )\n",
        "\n",
        "\n",
        "    def filter_func(input, label):\n",
        "      # Replace 'overrepresented_class' with the actual class label\n",
        "      # Replace 'keep_prob' with the probability of keeping an instance of the overrepresented class\n",
        "      return tf.cond(tf.equal(label, 0),\n",
        "                    lambda: tf.less(tf.random.uniform(shape=[], minval=0, maxval=1), 0.5),\n",
        "                    lambda: tf.constant(True))\n",
        "\n",
        "\n",
        "    # Apply the filter\n",
        "    # Unbatch the dataset if it's already batched\n",
        "    dataset = dataset.unbatch()\n",
        "\n",
        "    # Apply the filter function\n",
        "    filtered_dataset = dataset.filter(filter_func)\n",
        "\n",
        "    # Re-batch the dataset\n",
        "    batch_size = 128  # Or your desired batch size\n",
        "    filtered_dataset = filtered_dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "    return dataset, window_size, class_weights\n",
        "\n",
        "\n",
        "dataset, window_size, class_weights = dataset_from_files(\n",
        "    [\"/content/EEG_octo/dataset/train_S002_night1_hackathon_raw.mat\",\n",
        "    \"/content/EEG_octo/dataset/train_S003_night5_hackathon_raw.mat\"\n",
        "    ],\n",
        "    [\"/content/EEG_octo/dataset/train_S002_labeled.csv\",\n",
        "    \"/content/EEG_octo/dataset/train_S003_labeled.csv\"\n",
        "    ],\n",
        "    sampling_freq=250,\n",
        "    resampling_freq=20,\n",
        "    target_label=\"SS1\",\n",
        "    frequency_band=(8, 16),\n",
        "    window_size_in_seconds=2.5,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa572fe2",
      "metadata": {
        "id": "aa572fe2"
      },
      "source": [
        "\n",
        "#### Model\n",
        "\n",
        "The chosen model is an LSTM, since we are dealing with timeframes, LSTM are known to deal well with time depending samples. A k-cross validation is implemented, partitioning the data into 5 parts and alterning between the 4 parts for training and the 1 for testing.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d58c9783",
      "metadata": {
        "id": "d58c9783"
      },
      "outputs": [],
      "source": [
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "        self.f1_score = self.add_weight(name='f1', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        self.f1_score.assign(2 * ((p * r) / (p + r + tf.keras.backend.epsilon())))\n",
        "\n",
        "    def result(self):\n",
        "        return self.f1_score\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "        self.f1_score.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "062e6a1a-72af-4fe7-a1cc-ae81ace437eb",
      "metadata": {
        "id": "062e6a1a-72af-4fe7-a1cc-ae81ace437eb"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    input_layer = keras.Input(shape=(window_size, 6))\n",
        "\n",
        "    # Input layer for the EEG time series\n",
        "    input_eeg = Lambda(lambda y: y[:, :, 0:2])(input_layer)\n",
        "\n",
        "    # Layer normalization for EEG\n",
        "    norm_eeg = LayerNormalization()(input_eeg)\n",
        "\n",
        "    x = Conv1D(\n",
        "        filters=32, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\"\n",
        "    )(norm_eeg)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv1D(\n",
        "        filters=64, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv1D(\n",
        "        filters=128, kernel_size=5, strides=1, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Now you can flatten the output if you haven't applied global pooling before\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Input layer for the other features\n",
        "    first_elements = Lambda(lambda y: y[:, 0, 2:])(input_layer)\n",
        "    # Concatenate the CNN output and the first elements of the other features\n",
        "    concatenated = concatenate([x, first_elements])\n",
        "\n",
        "    x = Dense(\n",
        "        2048, activation=\"relu\",\n",
        "        kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "        bias_regularizer=regularizers.L2(1e-4),\n",
        "    )(concatenated)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(\n",
        "        1024,\n",
        "        activation=\"relu\",\n",
        "        kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "        bias_regularizer=regularizers.L2(1e-4),\n",
        "    )(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(\n",
        "        128,\n",
        "        activation=\"relu\",\n",
        "        kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "        bias_regularizer=regularizers.L2(1e-4),\n",
        "    )(x)\n",
        "    output_layer = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7637f27c-9443-47ce-87c3-879d60a2caa6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "7637f27c-9443-47ce-87c3-879d60a2caa6",
        "outputId": "e296802f-52a6-4d05-8ee5-35697bba8326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (50, 6)\n",
            "Shape of y: ()\n",
            "Shape of x: (50, 6)\n",
            "Shape of y: ()\n",
            "Shape of x: (50, 6)\n",
            "Shape of y: ()\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, 50, 6), found shape=(None, 6)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b739be89dfe8>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, 50, 6), found shape=(None, 6)\n"
          ]
        }
      ],
      "source": [
        "for x, y in dataset.take(3):\n",
        "    print(\"Shape of x:\", x.shape)\n",
        "    print(\"Shape of y:\", y.shape)\n",
        "\n",
        "\n",
        "# Define the model architecture\n",
        "model = create_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(),\n",
        "        tf.keras.metrics.Recall(),\n",
        "        F1Score(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    dataset,\n",
        "    epochs=30,\n",
        "    class_weight={label: weight for label, weight in enumerate(class_weights)}\n",
        ")\n",
        "\n",
        "\n",
        "training_f1_scores = history.history['f1_score']\n",
        "validation_f1_scores = history.history['val_f1_score']\n",
        "\n",
        "plt.plot(training_f1_scores, label='Training F1 Score')\n",
        "plt.plot(validation_f1_scores, label='Validation F1 Score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}