{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9364591e",
   "metadata": {},
   "source": [
    "# Sleep Spindle Detection\n",
    "## Data Preparation\n",
    "\n",
    "This notebook contains the preprocessing steps required for a sleep study dataset focusing on sleep spindles. The labels for sleep spindles are processed first, with the aim of identifying periods where sleep spindles are marked as present (`1`) or non-present (`0`). Various preprocessing steps, which are included in the `prepare_data()` function, can be applied to the data before training the model. Epochs are created around the marked events, each lasting for 2.5 seconds to match the reported duration of sleep spindles in the literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne  \n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import utils\n",
    "import feature_extraction\n",
    "from scipy.signal import detrend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097631c9",
   "metadata": {},
   "source": [
    "\n",
    "#### Data Preparation Function\n",
    "\n",
    "The `prepare_data` function is responsible for preparing EEG data by loading raw EEG recordings, applying preprocessing steps, and extracting epochs based on event markers. This process usually includes filtering to remove noise and artifacts, normalizing the data, and aligning the data with event markers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b493f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filepath_raw, filepath_labels, labels=None):\n",
    "    raw, raw_data, labels_df = utils.load_data(filepath_raw, filepath_labels)\n",
    "    #Optional features\n",
    "    \n",
    "    # raw._data = vdm_raw(raw)\n",
    "    # raw = raw.copy().crop(tmin=start_crop, tmax=end_crop)\n",
    "    # raw.filter(4, 35)\n",
    "    # raw = raw.notch_filter(50)\n",
    "    #Detrend optional\n",
    "    # normalize = scaler.fit_transform(raw.get_data()[0,:].reshape(-1, 1)).flatten()\n",
    "    # raw._data = detrend(raw.get_data())\n",
    "\n",
    "    labels_df = pd.read_csv(filepath_labels)\n",
    "    labels_df.sort_values(\"Timestamp\", inplace=True)\n",
    "    # labels_df = process_eeg_events(labels_df, start_crop, end_crop, raw.info['sfreq'])\n",
    "    if (labels):\n",
    "        labels_df = labels_df[['Timestamp','Epochs'] + labels]\n",
    "        time_events = labels_df.loc[(labels_df[labels[1]] == 1) | (labels_df[labels[0]] == 1),'Timestamp']\n",
    "        labels_events = labels_df.loc[(labels_df[labels[1]] == 1) | (labels_df[labels[0]] == 1),labels[1]]\n",
    "        events= np.column_stack((time_events, \n",
    "                                np.full(len(time_events), 1, dtype=int), \n",
    "                                labels_events))\n",
    "        epochs = mne.Epochs(raw, \n",
    "                        events, \n",
    "                        tmin=-0.5, \n",
    "                        tmax=2,\n",
    "                        baseline=None, \n",
    "                        preload=True)\n",
    "        num_epochs = len(time_events)\n",
    "        labels_events = np.zeros(num_epochs)\n",
    "        for i, epoch in enumerate(epochs):\n",
    "            if epochs.events[i, 2] == 1:\n",
    "                labels_events[i] = 1\n",
    "        epochs = normalize_epochs(epochs)\n",
    "        return {'Epochs': epochs, 'Labels': labels_events}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83bf27",
   "metadata": {},
   "source": [
    "#### Combining Data\n",
    "\n",
    "The epochs data is combined to the features extracted in the previous section. We need to combine them respecting the input model format (n_samples, n_features, n_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_data(raw_filepaths, label_filepaths, labels, fmin, fmax):\n",
    "    all_epochs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Loop through each file path, prepare data, and collect epochs and labels\n",
    "    for raw_filepath, label_filepath in zip(raw_filepaths, label_filepaths):\n",
    "        data = utils.prepare_data(raw_filepath, label_filepath, labels)\n",
    "        all_epochs.append(data['Epochs'])\n",
    "        all_labels.append(data['Labels'])\n",
    "\n",
    "    # Combine epochs and labels from all datasets\n",
    "    combined_epochs = mne.concatenate_epochs(all_epochs)\n",
    "    combined_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Extract features for all combined epochs\n",
    "    X = feature_extraction.get_raw_feature_all(all_epochs, fmin, fmax)\n",
    "\n",
    "    return X, combined_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
