{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783e24cf",
   "metadata": {},
   "source": [
    "\n",
    "# Sleep Spindle Study\n",
    "\n",
    "## Building Model\n",
    "\n",
    "In this notebook, we build a model to detect the presence of sleep spindles in the entire EEG recording. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44cdde",
   "metadata": {},
   "source": [
    "\n",
    "## Imports\n",
    "\n",
    "We will import the necessary libraries that are needed for processing the data, building the model, and evaluating its performance.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31dceae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 15:14:37.047760: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-30 15:14:37.092911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 15:14:37.092959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 15:14:37.093863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 15:14:37.100125: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-30 15:14:37.100745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-30 15:14:38.082027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "import utils\n",
    "import feature_extraction\n",
    "import data_preparation\n",
    "from memory_profiler import profile\n",
    "import preprocess\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import json\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM, Dense, BatchNormalization, Flatten\n",
    "import tensorflow.keras.layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5642274",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "Using the `processed_data` function from the previous step to download our concatenated raw with its correspondent preprocessing and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18bae3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=1, n_times=4965399\n",
      "    Range : 0 ... 4965398 =      0.000 ... 19861.592 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Used Annotations descriptions: ['0_0', '0_1', '1_0']\n",
      "Not setting metadata\n",
      "1191 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1191 events and 626 original time points ...\n",
      "0 bad epochs dropped\n",
      "epcohs.get_data().shape: (1191, 1, 626)\n",
      "raw_data.shape: (1, 4965399)\n",
      "len(labels_df.index): 1191\n",
      "Using data from preloaded Raw for 1191 events and 626 original time points ...\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=5772730\n",
      "    Range : 0 ... 5772729 =      0.000 ... 23090.916 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Used Annotations descriptions: ['0_0', '0_1', '1_0']\n",
      "Not setting metadata\n",
      "1050 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1050 events and 626 original time points ...\n",
      "0 bad epochs dropped\n",
      "epcohs.get_data().shape: (1050, 1, 626)\n",
      "raw_data.shape: (1, 5772730)\n",
      "len(labels_df.index): 1050\n",
      "Using data from preloaded Raw for 1050 events and 626 original time points ...\n",
      "Using data from preloaded Raw for 1191 events and 626 original time points ...\n",
      "Using data from preloaded Raw for 1050 events and 626 original time points ...\n",
      "Not setting metadata\n",
      "2241 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "X, labels = data_preparation.processed_data([\"../dataset/train_S002_night1_hackathon_raw.mat\",\n",
    "                                            \"../dataset/train_S003_night5_hackathon_raw.mat\"\n",
    "                                            ],\n",
    "                                            [\"../dataset/train_S002_labeled.csv\",\n",
    "                                            \"../dataset/train_S003_labeled.csv\"\n",
    "                                            ],\n",
    "                                            labels=[\"K0\", \"K1\"],\n",
    "                                            fmin=8,\n",
    "                                            fmax=16,\n",
    "                                            include_entire_recording=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa572fe2",
   "metadata": {},
   "source": [
    "\n",
    "#### Model\n",
    "\n",
    "The chosen model is an LSTM, since we are dealing with timeframes, LSTM are known to deal well with time depending samples. A k-cross validation is implemented, partitioning the data into 5 parts and alterning between the 4 parts for training and the 1 for testing.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58c9783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2241, 1, 626)\n",
      "labels.shape: (2241, 2)\n",
      "shape before reshaping: (2241, 1, 626)\n",
      "shape after reshaping: (2241, 626, 1)\n"
     ]
    }
   ],
   "source": [
    "class F1Score(Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "        self.f1_score = self.add_weight(name='f1', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        self.f1_score.assign(2 * ((p * r) / (p + r + tf.keras.backend.epsilon())))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1_score\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "        self.f1_score.assign(0)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"labels.shape:\", labels.shape)\n",
    "print(\"shape before reshaping:\", X.shape)\n",
    "X = X.transpose((0, 2, 1))\n",
    "print(\"shape after reshaping:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e6a1a-72af-4fe7-a1cc-ae81ace437eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = keras.Input(shape=(X.shape[1], X.shape[2]))\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=32, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "    )(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=64, kernel_size=3, strides=1, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=128, kernel_size=5, strides=1, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Now you can flatten the output if you haven't applied global pooling before\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(\n",
    "        2048, activation=\"relu\"\n",
    "    )(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(\n",
    "        1024, activation=\"relu\"\n",
    "    )(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(\n",
    "        128, activation=\"relu\"\n",
    "    )(x)\n",
    "    output_layer = Dense(labels.shape[1], activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637f27c-9443-47ce-87c3-879d60a2caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train indices: (1494,)\n",
      "test indices: (747,)\n",
      "Epoch 1/30\n",
      "47/47 [==============================] - 86s 2s/step - loss: 43.2846 - accuracy: 0.4351 - precision_6: 0.1506 - recall_6: 0.5488 - f1_score: 0.2363 - val_loss: 15.7417 - val_accuracy: 0.1673 - val_precision_6: 0.1539 - val_recall_6: 0.5897 - val_f1_score: 0.2442\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 82s 2s/step - loss: 9.7842 - accuracy: 0.4498 - precision_6: 0.1754 - recall_6: 0.6390 - f1_score: 0.2752 - val_loss: 7.0650 - val_accuracy: 0.2892 - val_precision_6: 0.1539 - val_recall_6: 0.5897 - val_f1_score: 0.2442\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 87s 2s/step - loss: 5.7390 - accuracy: 0.4826 - precision_6: 0.1700 - recall_6: 0.6195 - f1_score: 0.2668 - val_loss: 4.6634 - val_accuracy: 0.1687 - val_precision_6: 0.1566 - val_recall_6: 0.6000 - val_f1_score: 0.2484\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 87s 2s/step - loss: 3.8916 - accuracy: 0.4398 - precision_6: 0.1667 - recall_6: 0.6073 - f1_score: 0.2616 - val_loss: 3.2544 - val_accuracy: 0.1914 - val_precision_6: 0.1566 - val_recall_6: 0.6000 - val_f1_score: 0.2484\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 91s 2s/step - loss: 2.8215 - accuracy: 0.4766 - precision_6: 0.1734 - recall_6: 0.6317 - f1_score: 0.2721 - val_loss: 2.3964 - val_accuracy: 0.5221 - val_precision_6: 0.1593 - val_recall_6: 0.6103 - val_f1_score: 0.2527\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 91s 2s/step - loss: 2.0917 - accuracy: 0.4779 - precision_6: 0.1814 - recall_6: 0.6610 - f1_score: 0.2847 - val_loss: 1.8222 - val_accuracy: 0.4685 - val_precision_6: 0.1620 - val_recall_6: 0.6205 - val_f1_score: 0.2569\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 82s 2s/step - loss: 1.6683 - accuracy: 0.4746 - precision_6: 0.1680 - recall_6: 0.6122 - f1_score: 0.2637 - val_loss: 1.5180 - val_accuracy: 0.1566 - val_precision_6: 0.1566 - val_recall_6: 0.6000 - val_f1_score: 0.2484\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 90s 2s/step - loss: 1.3689 - accuracy: 0.3481 - precision_6: 0.1687 - recall_6: 0.6146 - f1_score: 0.2647 - val_loss: 1.2425 - val_accuracy: 0.5863 - val_precision_6: 0.1526 - val_recall_6: 0.5846 - val_f1_score: 0.2420\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 86s 2s/step - loss: 1.1847 - accuracy: 0.4257 - precision_6: 0.1727 - recall_6: 0.6293 - f1_score: 0.2710 - val_loss: 1.1560 - val_accuracy: 0.3079 - val_precision_6: 0.1727 - val_recall_6: 0.6615 - val_f1_score: 0.2739\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 85s 2s/step - loss: 1.0304 - accuracy: 0.4618 - precision_6: 0.1747 - recall_6: 0.6366 - f1_score: 0.2742 - val_loss: 0.9482 - val_accuracy: 0.1928 - val_precision_6: 0.1593 - val_recall_6: 0.6103 - val_f1_score: 0.2527\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 84s 2s/step - loss: 0.9058 - accuracy: 0.4331 - precision_6: 0.1673 - recall_6: 0.6098 - f1_score: 0.2626 - val_loss: 0.8142 - val_accuracy: 0.3133 - val_precision_6: 0.1714 - val_recall_6: 0.6564 - val_f1_score: 0.2718\n",
      "Epoch 12/30\n",
      " 3/47 [>.............................] - ETA: 1:17 - loss: 0.6905 - accuracy: 0.3542 - precision_6: 0.0625 - recall_6: 0.4286 - f1_score: 0.1091"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "for fold_no, (train, test) in enumerate(kfold.split(X, labels)):\n",
    "    print(\"train indices:\", train.shape)\n",
    "    print(\"test indices:\", test.shape)\n",
    "    # Define the model architecture\n",
    "    model = create_model()\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            F1Score(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X[train],\n",
    "        labels[train],\n",
    "        epochs=30,\n",
    "        validation_data=(X[test], labels[test]),\n",
    "    )\n",
    "\n",
    "\n",
    "    training_f1_scores = history.history['f1_score']\n",
    "    validation_f1_scores = history.history['val_f1_score']\n",
    "\n",
    "    plt.plot(training_f1_scores, label='Training F1 Score')\n",
    "    plt.plot(validation_f1_scores, label='Validation F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
